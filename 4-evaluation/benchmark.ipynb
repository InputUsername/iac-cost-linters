{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "import timeit\n",
    "import time\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../2-pattern-extraction/pattern_occurrences.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    occurrences = {}\n",
    "    for row in reader:\n",
    "        if row['pattern'] not in occurrences:\n",
    "            occurrences[row['pattern']] = []\n",
    "        occurrences[row['pattern']].append(row['url'])\n",
    "\n",
    "with open('../1-coding/diffs.json', 'r') as f:\n",
    "    diffs = json.load(f)\n",
    "    filenames = {\n",
    "        d['url']: [\n",
    "            f['filename'] for f in d['files']\n",
    "        ]\n",
    "        for d in diffs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKOV_CHECKS = {\n",
    "    'Object storage lifecycle rules': [\n",
    "        'CKV2_AWS_61',\n",
    "    ],\n",
    "    'AWS - Expensive DynamoDB': [\n",
    "        'CKV_AWS_801',\n",
    "        'CKV_AWS_802',\n",
    "        'CKV_AWS_803',\n",
    "    ],\n",
    "    'Old generation': [\n",
    "        'CKV_AWS_804',\n",
    "    ],\n",
    "}\n",
    "CHECKOV_CHECKS_PARAM = ','.join(','.join(checks) for checks in CHECKOV_CHECKS.values())\n",
    "CHECKOV_PATTERNS = {\n",
    "    check: pattern\n",
    "    for pattern, checks in CHECKOV_CHECKS.items()\n",
    "    for check in checks\n",
    "}\n",
    "\n",
    "checkov_stats = []\n",
    "\n",
    "N = sum(len(o) for p, o in occurrences.items() if p in CHECKOV_CHECKS.keys())\n",
    "i = 0\n",
    "\n",
    "for pattern, occs in occurrences.items():\n",
    "    if pattern not in CHECKOV_CHECKS.keys():\n",
    "        continue\n",
    "\n",
    "    for url in occs:\n",
    "        print(f'- [{i+1}/{N}] {pattern}: {url}')\n",
    "\n",
    "        _, _, _, owner, name, _, sha = url.split('/')\n",
    "\n",
    "        snapshot_path = f'snapshots/{owner}-{name}-{sha}'\n",
    "\n",
    "        summary = {\n",
    "            'pattern': pattern,\n",
    "            'url': url,\n",
    "            'before': []\n",
    "        }\n",
    "\n",
    "        for version in os.listdir(snapshot_path):\n",
    "            if version == 'latest' and url.startswith('https://github.com/ministryofjustice/cloud-platform-environments'):\n",
    "                print('  * Ignoring `latest`')\n",
    "                summary['latest'] = None\n",
    "                continue\n",
    "\n",
    "            version_path = f'{snapshot_path}/{version}/'\n",
    "\n",
    "            print(f'  * Running checkov against `{version}`')\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            result = subprocess.run([\n",
    "                'checkov',\n",
    "                '--evaluate-variables', 'true',\n",
    "                '--download-external-modules', 'true',\n",
    "                '--external-modules-download-path', '/tmp/',\n",
    "                '--directory', version_path,\n",
    "                '--check', CHECKOV_CHECKS_PARAM,\n",
    "                '-o', 'json',\n",
    "                '--framework', 'terraform',\n",
    "            ], capture_output=True, encoding='utf-8')\n",
    "\n",
    "            end = timeit.default_timer()\n",
    "\n",
    "            stdout = json.loads(result.stdout)\n",
    "\n",
    "            if 'results' not in stdout or 'summary' not in stdout:\n",
    "                print('    NO RESULTS:', stdout)\n",
    "                matched_patterns = []\n",
    "                files = []\n",
    "                has_errors = False\n",
    "            else:\n",
    "                failed_checks = stdout['results']['failed_checks']\n",
    "                matched_patterns = list(set(CHECKOV_PATTERNS[check['check_id']] for check in failed_checks))\n",
    "                files = [\n",
    "                    {\n",
    "                        'pattern': CHECKOV_PATTERNS[check['check_id']],\n",
    "                        'path': check['file_abs_path'],\n",
    "                        'lines': check['file_line_range'],\n",
    "                    }\n",
    "                    for check in failed_checks\n",
    "                ]\n",
    "                has_errors = stdout['summary']['parsing_errors'] != 0\n",
    "\n",
    "            if version == 'after':\n",
    "                summary['after'] = {\n",
    "                    'matched': matched_patterns,\n",
    "                    'errors': has_errors,\n",
    "                    'duration': end - start,\n",
    "                    'id': sha,\n",
    "                    'files': files,\n",
    "                }\n",
    "            elif version.startswith('before'):\n",
    "                summary['before'].append({\n",
    "                    'matched': matched_patterns,\n",
    "                    'errors': has_errors,\n",
    "                    'duration': end - start,\n",
    "                    'id': version.split('-')[1],\n",
    "                    'files': files,\n",
    "                })\n",
    "            elif version == 'latest':\n",
    "                summary['latest'] = {\n",
    "                    'matched': matched_patterns,\n",
    "                    'errors': has_errors,\n",
    "                    'duration': end - start,\n",
    "                    'id': 'latest',\n",
    "                    'files': files,\n",
    "                }\n",
    "\n",
    "            print(f'    Done after {end - start:.2f}s')\n",
    "\n",
    "        checkov_stats.append(summary)\n",
    "\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_df = pl.DataFrame(checkov_stats)\n",
    "\n",
    "with pl.Config(tbl_rows=150, tbl_width_chars=500):\n",
    "    print(checkov_df)\n",
    "\n",
    "checkov_df.write_json(f'results/checkov_{TIMESTAMP}.json', row_oriented=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFLint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLINT_RULES = {\n",
    "    'Budget': [\n",
    "        'cost_aws_budget',\n",
    "        'cost_google_budget'\n",
    "    ],\n",
    "    'Object storage lifecycle rules': [\n",
    "        'cost_aws_object_storage_lifecycle_rule',\n",
    "    ],\n",
    "    'Old generation': [\n",
    "        'cost_aws_old_generation',\n",
    "    ],\n",
    "    'AWS - Expensive DynamoDB': [\n",
    "        'cost_aws_expensive_dynamodb',\n",
    "    ],\n",
    "}\n",
    "TFLINT_PATTERNS = {\n",
    "    rule: pattern\n",
    "    for pattern, rules in TFLINT_RULES.items()\n",
    "    for rule in rules\n",
    "}\n",
    "TFLINT_RULES_PARAMS = [\n",
    "    f'--only={rule}'\n",
    "    for rules in TFLINT_RULES.values()\n",
    "    for rule in rules\n",
    "]\n",
    "\n",
    "tflint_stats = []\n",
    "\n",
    "N = sum(len(o) for p, o in occurrences.items() if p in TFLINT_RULES.keys())\n",
    "i = 0\n",
    "\n",
    "for pattern, occs in occurrences.items():\n",
    "    if pattern not in TFLINT_RULES.keys():\n",
    "        continue\n",
    "\n",
    "    for url in occs:\n",
    "        print(f'- [{i+1}/{N}] {pattern}: {url}')\n",
    "\n",
    "        _, _, _, owner, name, _, sha = url.split('/')\n",
    "\n",
    "        snapshot_path = f'snapshots/{owner}-{name}-{sha}'\n",
    "\n",
    "        summary = {\n",
    "            'pattern': pattern,\n",
    "            'url': url,\n",
    "            'before': []\n",
    "        }\n",
    "\n",
    "        for version in os.listdir(snapshot_path):\n",
    "            # if version == 'latest':\n",
    "            #     continue\n",
    "\n",
    "            version_path = f'{snapshot_path}/{version}/'\n",
    "\n",
    "            print(f'  * Running tflint against `{version}`')\n",
    "\n",
    "            print('    terraform get')\n",
    "\n",
    "            terraform_result = subprocess.run(['terraform', f'-chdir={version_path}', 'get'], capture_output=True, encoding='utf-8')\n",
    "\n",
    "            print(f'    terraform get returned with status {terraform_result.returncode}')\n",
    "\n",
    "            print('    Starting tflint')\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            result = subprocess.run([\n",
    "                'tflint',\n",
    "                '--format=json',\n",
    "                '--call-module-type=all',\n",
    "                '--enable-plugin=cost',\n",
    "                *TFLINT_RULES_PARAMS,\n",
    "                f'--recursive'\n",
    "            ], capture_output=True, encoding='utf-8', cwd=version_path)\n",
    "\n",
    "            end = timeit.default_timer()\n",
    "\n",
    "            stdout = json.loads(result.stdout)\n",
    "            issues = stdout['issues']\n",
    "            matched_patterns = [TFLINT_PATTERNS[issue['rule']['name']] for issue in issues]\n",
    "            files = [\n",
    "                {\n",
    "                    'pattern': TFLINT_PATTERNS[issue['rule']['name']],\n",
    "                    'path': version_path + issue['range']['filename'],\n",
    "                    'start': issue['range']['start'],\n",
    "                    'end': issue['range']['end'],\n",
    "                }\n",
    "                for issue in issues\n",
    "            ]\n",
    "            has_errors = len(stdout['errors']) != 0\n",
    "\n",
    "            if version == 'after':\n",
    "                summary['after'] = {\n",
    "                    'matched': matched_patterns,\n",
    "                    'errors': has_errors,\n",
    "                    'duration': end - start,\n",
    "                    'id': sha,\n",
    "                    'files': files,\n",
    "                }\n",
    "            elif version.startswith('before'):\n",
    "                summary['before'].append({\n",
    "                    'matched': matched_patterns,\n",
    "                    'errors': has_errors,\n",
    "                    'duration': end - start,\n",
    "                    'id': version.split('-')[1],\n",
    "                    'files': files,\n",
    "                })\n",
    "            elif version == 'latest':\n",
    "                summary['latest'] = {\n",
    "                    'matched': matched_patterns,\n",
    "                    'errors': has_errors,\n",
    "                    'duration': end - start,\n",
    "                    'id': 'latest',\n",
    "                    'files': files,\n",
    "                }\n",
    "\n",
    "            print(f'    Done after {end - start:.2f}s')\n",
    "\n",
    "        tflint_stats.append(summary)\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflint_df = pl.DataFrame(tflint_stats)\n",
    "\n",
    "with pl.Config(tbl_rows=150, tbl_width_chars=500):\n",
    "    print(tflint_df)\n",
    "\n",
    "tflint_df.write_json(f'results/tflint_{TIMESTAMP}.json', row_oriented=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
