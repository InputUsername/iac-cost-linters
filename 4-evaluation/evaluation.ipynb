{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import polars as pl\n",
    "\n",
    "results_checkov = pl.read_json(f'results/checkov_1721775655.json')\n",
    "results_tflint = pl.read_json(f'results/tflint_1721775655.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKOV_PATTERNS = [\n",
    "    'Object storage lifecycle rules',\n",
    "    'Old generation',\n",
    "    'AWS - Expensive DynamoDB',\n",
    "]\n",
    "\n",
    "TFLINT_PATTERNS = [\n",
    "    'Budget',\n",
    "    'Object storage lifecycle rules',\n",
    "    'Old generation',\n",
    "    'AWS - Expensive DynamoDB',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision/recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_clean = results_checkov.filter([\n",
    "        pl.col('before').list.len() != 0,\n",
    "        pl.col('before').list.get(0).struct.field('errors').not_(),\n",
    "        pl.col('after').struct.field('errors').not_(),\n",
    "    ])\n",
    "\n",
    "tp = defaultdict(int)\n",
    "fp = defaultdict(int)\n",
    "fn = defaultdict(int)\n",
    "\n",
    "for real_pattern, url, before, _, _ in checkov_clean.iter_rows():\n",
    "    matched_patterns = before[0]['matched']\n",
    "\n",
    "    for pat in CHECKOV_PATTERNS:\n",
    "        if pat == real_pattern and pat in matched_patterns:\n",
    "            tp[pat] += 1\n",
    "\n",
    "        if pat != real_pattern and pat in matched_patterns:\n",
    "            fp[pat] += 1\n",
    "\n",
    "            print('----------')\n",
    "            print('false positive:', url)\n",
    "            print('commit:', before[0]['id'])\n",
    "            print('real:', real_pattern)\n",
    "            print('matched:', matched_patterns)\n",
    "            for file in before[0]['files']:\n",
    "                print(file['pattern'], '-', file['lines'], '-', file['path'])\n",
    "\n",
    "        if pat == real_pattern and pat not in matched_patterns:\n",
    "            fn[pat] += 1\n",
    "\n",
    "            print('----------')\n",
    "            print('false positive:', before[0]['id'])\n",
    "            print('real:', real_pattern)\n",
    "            print('matched:', matched_patterns)\n",
    "            for file in before[0]['files']:\n",
    "                print(file['pattern'], '-', file['lines'], '-', file['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = []\n",
    "for pat in CHECKOV_PATTERNS:\n",
    "    pr.append({\n",
    "        'pattern': pat,\n",
    "        'precision': tp[pat] / (tp[pat] + fp[pat]),\n",
    "        'recall': tp[pat] / (tp[pat] + fn[pat]),\n",
    "    })\n",
    "\n",
    "counts_df = checkov_clean.group_by('pattern').len()\n",
    "measures_df = pl.DataFrame([\n",
    "    {\n",
    "        'pattern': p,\n",
    "        'tp': tp[p],\n",
    "        'fp': fp[p],\n",
    "        'fn': fn[p],\n",
    "    }\n",
    "    for p in CHECKOV_PATTERNS\n",
    "])\n",
    "pr_df = pl.DataFrame(pr)\n",
    "\n",
    "print(counts_df.join(measures_df, on='pattern').join(pr_df, on='pattern'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before + after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = defaultdict(int)\n",
    "fp = defaultdict(int)\n",
    "fn = defaultdict(int)\n",
    "\n",
    "for real_pattern, _, before, after, _ in checkov_clean.iter_rows():\n",
    "    matched_before = before[0]['matched']\n",
    "    matched_after = after['matched']\n",
    "\n",
    "    for pat in CHECKOV_PATTERNS:\n",
    "        if pat == real_pattern and pat in matched_before:\n",
    "            tp[pat] += 1\n",
    "        if pat != real_pattern and pat in matched_before:\n",
    "            fp[pat] += 1\n",
    "        if pat == real_pattern and pat not in matched_before:\n",
    "            fn[pat] += 1\n",
    "\n",
    "        if pat in matched_after:\n",
    "            fp[pat] += 1\n",
    "\n",
    "pr = []\n",
    "for pat in CHECKOV_PATTERNS:\n",
    "    pr.append({\n",
    "        'pattern': pat,\n",
    "        'precision': tp[pat] / (tp[pat] + fp[pat]),\n",
    "        'recall': tp[pat] / (tp[pat] + fn[pat]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = []\n",
    "for pat in CHECKOV_PATTERNS:\n",
    "    pr.append({\n",
    "        'pattern': pat,\n",
    "        'precision': tp[pat] / (tp[pat] + fp[pat]),\n",
    "        'recall': tp[pat] / (tp[pat] + fn[pat]),\n",
    "    })\n",
    "\n",
    "counts_df = checkov_clean.group_by('pattern').len()\n",
    "measures_df = pl.DataFrame([\n",
    "    {\n",
    "        'pattern': p,\n",
    "        'tp': tp[p],\n",
    "        'fp': fp[p],\n",
    "        'fn': fn[p],\n",
    "    }\n",
    "    for p in CHECKOV_PATTERNS\n",
    "])\n",
    "pr_df = pl.DataFrame(pr)\n",
    "\n",
    "summary = counts_df.join(measures_df, on='pattern').join(pr_df, on='pattern')\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFLint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflint_clean = results_tflint.filter([\n",
    "        pl.col('before').list.len() != 0,\n",
    "        pl.col('before').list.get(0).struct.field('errors').not_(),\n",
    "        pl.col('after').struct.field('errors').not_(),\n",
    "    ])\n",
    "\n",
    "tp = defaultdict(int)\n",
    "fp = defaultdict(int)\n",
    "fn = defaultdict(int)\n",
    "\n",
    "for real_pattern, url, before, _, _ in tflint_clean.iter_rows():\n",
    "    matched_patterns = before[0]['matched']\n",
    "\n",
    "    for pat in TFLINT_PATTERNS:\n",
    "        if pat == real_pattern and pat in matched_patterns:\n",
    "            tp[pat] += 1\n",
    "\n",
    "        if pat != real_pattern and pat in matched_patterns:\n",
    "            fp[pat] += 1\n",
    "\n",
    "            print('----------')\n",
    "            print('false positive:', url)\n",
    "            print('commit:', before[0]['id'])\n",
    "            print('real:', real_pattern)\n",
    "            print('matched:', matched_patterns)\n",
    "            for file in before[0]['files']:\n",
    "                print(file['pattern'], '-', 'start:', file['start'], 'end:', file['end'], '-', file['path'])\n",
    "\n",
    "        if pat == real_pattern and pat not in matched_patterns:\n",
    "            fn[pat] += 1\n",
    "\n",
    "            print('----------')\n",
    "            print('false negative:', url)\n",
    "            print('commit:', before[0]['id'])\n",
    "            print('real:', real_pattern)\n",
    "            print('matched:', matched_patterns)\n",
    "            for file in before[0]['files']:\n",
    "                print(file['pattern'], '-', 'start:', file['start'], 'end:', file['end'], '-', file['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = []\n",
    "for pat in TFLINT_PATTERNS:\n",
    "    pr.append({\n",
    "        'pattern': pat,\n",
    "        'precision': tp[pat] / (tp[pat] + fp[pat]),\n",
    "        'recall': tp[pat] / (tp[pat] + fn[pat]),\n",
    "    })\n",
    "\n",
    "counts_df = tflint_clean.group_by('pattern').len()\n",
    "measures_df = pl.DataFrame([\n",
    "    {\n",
    "        'pattern': p,\n",
    "        'tp': tp[p],\n",
    "        'fp': fp[p],\n",
    "        'fn': fn[p],\n",
    "    }\n",
    "    for p in TFLINT_PATTERNS\n",
    "])\n",
    "pr_df = pl.DataFrame(pr)\n",
    "\n",
    "print(\n",
    "    counts_df.join(measures_df, on='pattern').join(pr_df, on='pattern')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before + after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = defaultdict(int)\n",
    "fp = defaultdict(int)\n",
    "fn = defaultdict(int)\n",
    "\n",
    "for real_pattern, _, before, after, _ in tflint_clean.iter_rows():\n",
    "    matched_before = before[0]['matched']\n",
    "    matched_after = after['matched']\n",
    "\n",
    "    for pat in TFLINT_PATTERNS:\n",
    "        if pat == real_pattern and pat in matched_before:\n",
    "            tp[pat] += 1\n",
    "        if pat != real_pattern and pat in matched_before:\n",
    "            fp[pat] += 1\n",
    "        if pat == real_pattern and pat not in matched_before:\n",
    "            fn[pat] += 1\n",
    "\n",
    "        if pat in matched_after:\n",
    "            fp[pat] += 1\n",
    "\n",
    "pr = []\n",
    "for pat in TFLINT_PATTERNS:\n",
    "    pr.append({\n",
    "        'pattern': pat,\n",
    "        'precision': tp[pat] / (tp[pat] + fp[pat]),\n",
    "        'recall': tp[pat] / (tp[pat] + fn[pat]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = []\n",
    "for pat in TFLINT_PATTERNS:\n",
    "    pr.append({\n",
    "        'pattern': pat,\n",
    "        'precision': tp[pat] / (tp[pat] + fp[pat]),\n",
    "        'recall': tp[pat] / (tp[pat] + fn[pat]),\n",
    "    })\n",
    "\n",
    "counts_df = tflint_clean.group_by('pattern').len()\n",
    "measures_df = pl.DataFrame([\n",
    "    {\n",
    "        'pattern': p,\n",
    "        'tp': tp[p],\n",
    "        'fp': fp[p],\n",
    "        'fn': fn[p],\n",
    "    }\n",
    "    for p in TFLINT_PATTERNS\n",
    "])\n",
    "pr_df = pl.DataFrame(pr)\n",
    "\n",
    "print(\n",
    "    counts_df.join(measures_df, on='pattern').join(pr_df, on='pattern')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkov + TFLint - Latest commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_matches = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "for url, latest in checkov_clean.select('url', 'latest').filter(pl.col('latest').is_not_null()).iter_rows():\n",
    "    for m in set(latest['matched']):\n",
    "        prefix, *_ = url.split('/commit/')\n",
    "        latest_matches[m]['checkov'].add(prefix)\n",
    "\n",
    "for url, latest in tflint_clean.select('url', 'latest').filter(pl.col('latest').is_not_null()).iter_rows():\n",
    "    for m in set(latest['matched']):\n",
    "        prefix, *_ = url.split('/commit/')\n",
    "        latest_matches[m]['tflint'].add(prefix)\n",
    "\n",
    "print(pl.DataFrame([\n",
    "    {\n",
    "        'pattern': pat,\n",
    "        'checkov': len(row['checkov']),\n",
    "        'tflint': len(row['tflint']),\n",
    "    }\n",
    "    for pat, row in latest_matches.items()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github, Auth\n",
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "with open('../1-coding/TOKEN.txt', 'r') as token_file:\n",
    "    token = token_file.readline().strip()\n",
    "    gh = Github(auth=Auth.Token(token))\n",
    "\n",
    "print('Using GitHub as', gh.get_user().login)\n",
    "\n",
    "latest_active_matches = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "now = datetime.now(tz=UTC)\n",
    "threshold = timedelta(days=183)\n",
    "\n",
    "for pat, row in latest_matches.items():\n",
    "    for tool, urls in row.items():\n",
    "        for url in urls:\n",
    "            try:\n",
    "                repo = gh.get_repo(url[19:])\n",
    "                if (now - repo.updated_at) <= threshold or (now - repo.pushed_at) <= threshold:\n",
    "                    latest_active_matches[pat][tool].add(url)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "print(pl.DataFrame([\n",
    "    {\n",
    "        'pattern': pat,\n",
    "        'checkov': len(row['checkov']),\n",
    "        'tflint': len(row['tflint'])\n",
    "    }\n",
    "    for pat, row in latest_active_matches.items()\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkov + TFLint - Rule match co-occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    checkov_clean.select(\n",
    "        'pattern',\n",
    "        before=pl.col('before').list.get(0).struct.field('matched').list.len() > 1,\n",
    "        after=pl.col('after').struct.field('matched').list.len() > 1,\n",
    "    ).group_by('pattern').sum()\n",
    ")\n",
    "\n",
    "print(\n",
    "    tflint_clean.select(\n",
    "        'pattern',\n",
    "        before=pl.col('before').list.get(0).struct.field('matched').list.len() > 1,\n",
    "        after=pl.col('after').struct.field('matched').list.len() > 1,\n",
    "    ).group_by('pattern').sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config(fmt_str_lengths=500, tbl_width_chars=500):\n",
    "    print(\n",
    "        results_checkov\n",
    "            .select(\n",
    "                'url',\n",
    "                duration_before=pl.col('before').list.get(0).struct.field('duration'),\n",
    "                duration_after=pl.col('after').struct.field('duration'),\n",
    "            )\n",
    "            .drop_nulls()\n",
    "            .top_k(10, by=['duration_before', 'duration_after'])\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        results_tflint\n",
    "            .select(\n",
    "                'url',\n",
    "                duration_before=pl.col('before').list.get(0).struct.field('duration'),\n",
    "                duration_after=pl.col('after').struct.field('duration'),\n",
    "            )\n",
    "            .drop_nulls()\n",
    "            .top_k(10, by=['duration_before', 'duration_after'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_perf = {\n",
    "    'before': results_checkov.select(duration=pl.col('before').list.get(0).struct.field('duration')).drop_nulls().get_column('duration').to_list(),\n",
    "    'after': results_checkov.select(duration=pl.col('after').struct.field('duration')).drop_nulls().get_column('duration').to_list(),\n",
    "    # 'latest': results_checkov.select(duration=pl.col('latest').struct.field('duration')).drop_nulls().get_column('duration').to_list(),\n",
    "}\n",
    "\n",
    "tflint_perf = {\n",
    "    'before': results_tflint.select(duration=pl.col('before').list.get(0).struct.field('duration')).drop_nulls().get_column('duration').to_list(),\n",
    "    'after': results_tflint.select(duration=pl.col('after').struct.field('duration')).drop_nulls().get_column('duration').to_list(),\n",
    "    # 'latest': results_tflint.select(duration=pl.col('latest').struct.field('duration')).drop_nulls().get_column('duration').to_list(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Checkov\\n* before:\\n    mean:',\n",
    "    statistics.mean(checkov_perf['before']),\n",
    "    '\\n    median:',\n",
    "    statistics.median(checkov_perf['before']),\n",
    "    '\\n* after:\\n    mean:',\n",
    "    statistics.mean(checkov_perf['after']),\n",
    "    '\\n    median:',\n",
    "    statistics.median(checkov_perf['after']),\n",
    ")\n",
    "\n",
    "print(\n",
    "    'TFLint\\n* before:\\n    mean:',\n",
    "    statistics.mean(tflint_perf['before']),\n",
    "    '\\n    median:',\n",
    "    statistics.median(tflint_perf['before']),\n",
    "    '\\n* after:\\n    mean:',\n",
    "    statistics.mean(tflint_perf['after']),\n",
    "    '\\n    median:',\n",
    "    statistics.median(tflint_perf['after']),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n",
    "\n",
    "bar_data_checkov = [statistics.mean(v) for v in checkov_perf.values()]\n",
    "bar_data_tflint = [statistics.mean(v) for v in tflint_perf.values()]\n",
    "\n",
    "keys = list(checkov_perf.keys())\n",
    "bar_width = 0.4\n",
    "x1 = np.arange(len(checkov_perf))\n",
    "x2 = np.arange(len(tflint_perf)) + len(checkov_perf) + bar_width\n",
    "\n",
    "bars1 = ax1.bar(x1, bar_data_checkov, bar_width, label='Checkov')\n",
    "ax1.bar_label(bars1, padding=3)\n",
    "ax1.set_title('Checkov')\n",
    "ax1.set_xticks(x1)\n",
    "ax1.set_xticklabels(keys)\n",
    "ax1.set_ylabel('Average inspection duration (s)')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(10**-1, 10**1.7)\n",
    "ax1.yaxis.set_major_formatter(FuncFormatter(lambda y,pos: ('{{:.{:1d}f}}'.format(int(np.maximum(-np.log10(y),0)))).format(y)))\n",
    "\n",
    "bars2 = ax2.bar(x2, bar_data_tflint, bar_width, label='TFLint', color='#348abd')\n",
    "ax2.bar_label(bars2, padding=3)\n",
    "ax2.set_title('TFLint')\n",
    "ax2.set_xticks(x2)\n",
    "ax2.set_xticklabels(keys)\n",
    "ax2.set_yscale('log')\n",
    "ax2.yaxis.set_major_formatter(FuncFormatter(lambda y,pos: ('{{:.{:1d}f}}'.format(int(np.maximum(-np.log10(y),0)))).format(y)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "keys = list(checkov_perf.keys())\n",
    "\n",
    "ax1.boxplot(list(checkov_perf.values()), showfliers=False)\n",
    "ax1.set_title('Checkov')\n",
    "ax1.set_xticklabels(keys)\n",
    "ax1.set_ylabel('Inspection duration (s)')\n",
    "\n",
    "ax2.boxplot(list(tflint_perf.values()), showfliers=False)\n",
    "ax2.set_title('TFLint')\n",
    "ax2.set_xticklabels(keys)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_lines(root_dir: str) -> int:\n",
    "    total = 0\n",
    "    for base, _, files in os.walk(root_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith(('.tf', '.tf.json')):\n",
    "                with open(os.path.join(base, filename), 'r') as f:\n",
    "                    total += sum(1 for _ in f)\n",
    "    return total\n",
    "\n",
    "durations_checkov_before = []\n",
    "lines_checkov_before = []\n",
    "\n",
    "for url, before in results_checkov.select('url', 'before').iter_rows():\n",
    "    if len(before) == 0:\n",
    "        continue\n",
    "\n",
    "    durations_checkov_before.append(before[0]['duration'])\n",
    "\n",
    "    _, _, _, owner, repo, _, sha = url.split('/')\n",
    "\n",
    "    snapshot_path = f'snapshots/{owner}-{repo}-{sha}'\n",
    "\n",
    "    for version in os.listdir(snapshot_path):\n",
    "        version_path = f'{snapshot_path}/{version}/'\n",
    "        if version.startswith('before'):\n",
    "            lines_checkov_before.append(count_lines(version_path))\n",
    "\n",
    "durations_tflint_before = []\n",
    "lines_tflint_before = []\n",
    "\n",
    "for url, before in results_tflint.select('url', 'before').iter_rows():\n",
    "    if len(before) == 0:\n",
    "        continue\n",
    "\n",
    "    durations_tflint_before.append(before[0]['duration'])\n",
    "\n",
    "    _, _, _, owner, repo, _, sha = url.split('/')\n",
    "\n",
    "    snapshot_path = f'snapshots/{owner}-{repo}-{sha}'\n",
    "\n",
    "    for version in os.listdir(snapshot_path):\n",
    "        version_path = f'{snapshot_path}/{version}/'\n",
    "        if version.startswith('before'):\n",
    "            lines_tflint_before.append(count_lines(version_path))\n",
    "\n",
    "assert len(durations_checkov_before) == len(lines_checkov_before)\n",
    "assert len(durations_tflint_before) == len(lines_tflint_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
    "\n",
    "ax1.scatter(y=durations_checkov_before, x=lines_checkov_before)\n",
    "ax1.set_title('Checkov')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylabel('Total inspection duration (s)')\n",
    "\n",
    "ax2.scatter(y=durations_tflint_before, x=lines_tflint_before, color='#348abd')\n",
    "ax2.set_title('TFLint')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "fig.supxlabel('Total lines of IaC code', color=ax1.yaxis.label.get_color())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
